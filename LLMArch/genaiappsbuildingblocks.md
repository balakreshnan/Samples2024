# Building blocks of Gen AI Applications in LLM/SLM

## Introduction

- How to build Gen AI Applications
- Which teams are involved and how they work together
- Create Gen AI Products
- Cross discipline teams to achieve end to end solutions
- Build Enterprise grade AI applications
- Build with confidence

## End to End building blocks

![info](https://github.com/balakreshnan/Samples2024/blob/main/LLMArch/images/genaiappbuildingblocks1.jpg 'RagChat')

### End to End building blocks explanation

- It all starts with business identifying use case and the problem statement
- Given the use case and we need to incorporate Gen AI, we need the data science or AI team to validate and build the AI framework/product/application for the use case
- Data science team will also evaluate the output and provide feedback to the business
- Will build responsible AI into the product
- Prodive Audit and compliance and governance baked in the product
- Will build the product with security in mind
- Will have a process to monitor and evaluate with new metrics to provide safer gen ai products
- Get feedback from the application build out and teams in real time when deployed to production
- Once the product is built from the AI/Data Science team, goes to Application building out team
- Most of the Gen AI will be Chat or Voice enabled natural language processing UX or some conversational UI
- Application team will build out other components like web/mobile etc
- Make sure it's production ready
- Once the product is built, it goes to the DevOps team
- DevOps team will deploy the product to production
- DevOps team will also monitor the product in production
- Devops will also work with infrastructure team to make sure the product is scalable and secure
- HA and DR will be part of the deployment
- Means to get product feedback and monitoring for Gen AI is critical

## Details (AI Generated Text)

### Building a Generation AI Application: A Step-by-Step Journey
 
Welcome to this comprehensive guide on constructing a Generation AI Application! Using the image provided as our roadmap, let's embark on a fascinating journey through the essential building blocks and processes. Together, we'll explore the roles of different teams, highlighting the key steps along the way. Let's begin!

### 1. The Beginning: Setting the Stage

Our journey begins with a clear starting point, where the vision of creating a Generation AI Application takes its first breath. The goal is clear, but the path must be planned meticulously.

#### 1. Business Team: Laying the Foundation

##### Use Case

- The first step is to identify the "Use Case." This is where we define the problem we aim to solve or the opportunity we want to seize. It’s crucial to have a clear understanding of the application’s purpose and the value it will bring.
Requirements
- Next, we gather the "Requirements." This involves understanding what features and functionalities are necessary to achieve our goals. It's about translating the use case into a tangible list of needs.
Stakeholders
- Engaging with "Stakeholders" is our next milestone. These are the individuals or groups who have a vested interest in the application. Their input and feedback are invaluable as we move forward.
Product Management
- With a defined use case, clear requirements, and stakeholder insights, we move to "Product Management." This is where we strategize the development process, ensuring all pieces are aligned and resources are effectively allocated.

#### 2. Data Science/Data/AI Team: The Heart of Intelligence

- The journey now transitions to the Data Science/Data/AI team. Here, we start with "LLM/SLM" (Large Language Models/Small Language Models), selecting the appropriate models for our application.
- We then focus on building a "Vector Index/DB," which acts as the backbone for data storage and retrieval. This step ensures that our application can efficiently access and utilize data.
- In addition to vector indexing, we identify and integrate "Other Data Sources" that the application may need. This comprehensive data gathering ensures a well-rounded and insightful AI model.
- "Evaluation" follows, where we rigorously test the models to ensure they meet the required standards. This phase is about fine-tuning and optimizing our AI components.
- After evaluation, we move to creating a "Model Catalog" and developing "Use Case Specific" models. This step tailors our AI to the specific needs of the application, enhancing its effectiveness.
- "LLM Ops" (Operations) come next, focusing on the deployment and maintenance of our models. It’s about ensuring they perform reliably in real-world scenarios.
Use Case API/Agents Deployment
- Finally, we deploy "Use Case API/Agents." This step integrates our AI models into the application, making them accessible and functional for end-users.

#### 3. Application Team: Bringing It All Together

- We now transition to the Application Team. The journey here begins with "APP UX" (User Experience). Designing an intuitive and engaging interface is crucial for user satisfaction.
- Next, we develop the "APP Middleware," which acts as the intermediary between the user interface and the backend systems. This ensures seamless communication and data flow.
- Building "Micro Services" is our next step. These are small, independent services that work together to form the application’s functionality. This approach enhances flexibility and scalability.
- We also focus on "Storage/DB," ensuring that all data is securely stored and easily retrievable. This step supports the application's data needs efficiently.
- "Testing" is a critical phase where we rigorously check the application for any issues or bugs. It’s about ensuring that everything works as expected before the final launch.
- "CI/CD" (Continuous Integration/Continuous Deployment) is our next focus. This process ensures that new code changes are automatically tested and deployed, maintaining the application's robustness and agility.
- Finally, we reach the "Deployment" phase. Here, the application is launched to the production environment, making it available for users to experience and benefit from.

#### 4. Cross-Cutting Concerns: Ensuring a Robust Foundation

- Throughout our journey, several cross-cutting concerns play a vital role in supporting the development process. These include:
- Ensuring that the application is secure from potential threats and vulnerabilities is paramount. Security measures are integrated at every stage to protect data and maintain user trust.
- Leveraging robust "Infrastructure/AI/Cloud" services ensures that our application is scalable, reliable, and capable of handling large volumes of data and users.
- Maintaining a "Code Repository" provides version control and collaboration capabilities, ensuring that all team members are aligned and that code changes are tracked.
- Implementing "Observability" tools allows us to monitor the application’s performance, detect issues in real time, and gain insights into user behavior.
- "Governance" ensures that all processes comply with regulatory requirements and best practices, maintaining the integrity and accountability of the project.

#### 5. The End: Reflecting on the Journey

- As we reach the end of our journey, we reflect on the meticulous planning, collaborative efforts, and innovative solutions that brought the Generation AI Application to life. Each team played a crucial role, contributing to a seamless and successful development process.

Thank you for joining us on this journey. By understanding and following these building blocks, you are well-equipped to embark on your own adventure in creating a Generation AI Application. Best of luck, and may your project be a resounding success.

## Conclusion

- Above can change based on the science advacement
- This is just a starting point
- Use it as guidance and adjust based on your requirements
- This is based on my experience and what I have seen in the industry
- Guidance is for production grade enterprise applications or products based on Gen AI